{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a201d0b1-501a-4cbd-b54c-c37e48f0af7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-23 19:23:53,067] A new study created in memory with name: no-name-1cf475f6-d460-4474-a62d-3e047ccd3e9c\n",
      "  0%|          | 0/50 [00:00<?, ?it/s][I 2025-05-23 19:24:01,914] Trial 0 finished with value: 0.27285459637641907 and parameters: {'learning_rate': 3.160185597673604e-05, 'batch_size': 64, 'epochs': 94, 'dropout1': 0.3105150017273445, 'dropout2': 0.2433671491183084, 'dropout3': 0.48491518295519387, 'dropout4': 0.1935499650043541, 'units1': 237, 'units2': 119, 'units3': 218, 'units4': 218, 'n_layers': 3}. Best is trial 0 with value: 0.27285459637641907.\n",
      "  2%|▏         | 1/50 [00:08<07:13,  8.84s/it][I 2025-05-23 19:24:06,027] Trial 1 finished with value: 0.2562015950679779 and parameters: {'learning_rate': 0.007615829512458913, 'batch_size': 32, 'epochs': 139, 'dropout1': 0.20121639853816428, 'dropout2': 0.10750102473880671, 'dropout3': 0.37419825800085327, 'dropout4': 0.3817923025078148, 'units1': 247, 'units2': 162, 'units3': 121, 'units4': 229, 'n_layers': 4}. Best is trial 1 with value: 0.2562015950679779.\n",
      "  4%|▍         | 2/50 [00:12<04:50,  6.06s/it][I 2025-05-23 19:24:19,099] Trial 2 finished with value: 0.25655701756477356 and parameters: {'learning_rate': 3.129686382373026e-05, 'batch_size': 16, 'epochs': 79, 'dropout1': 0.35210481892704226, 'dropout2': 0.3594553581136287, 'dropout3': 0.46211891704841157, 'dropout4': 0.38814684998314175, 'units1': 137, 'units2': 36, 'units3': 154, 'units4': 71, 'n_layers': 4}. Best is trial 1 with value: 0.2562015950679779.\n",
      "  6%|▌         | 3/50 [00:26<07:15,  9.26s/it][I 2025-05-23 19:24:24,590] Trial 3 finished with value: 0.26695650815963745 and parameters: {'learning_rate': 0.00047209442701714945, 'batch_size': 128, 'epochs': 72, 'dropout1': 0.5402063684035339, 'dropout2': 0.4588442099396499, 'dropout3': 0.36206041936674016, 'dropout4': 0.32114249413281615, 'units1': 117, 'units2': 239, 'units3': 226, 'units4': 114, 'n_layers': 3}. Best is trial 1 with value: 0.2562015950679779.\n",
      "  8%|▊         | 4/50 [00:31<05:57,  7.77s/it][I 2025-05-23 19:24:49,818] Trial 4 finished with value: 0.25712355971336365 and parameters: {'learning_rate': 2.7865303665391198e-05, 'batch_size': 16, 'epochs': 113, 'dropout1': 0.2744360497937144, 'dropout2': 0.14456218725353862, 'dropout3': 0.5381395491325439, 'dropout4': 0.17968943059720735, 'units1': 57, 'units2': 115, 'units3': 255, 'units4': 237, 'n_layers': 4}. Best is trial 1 with value: 0.2562015950679779.\n",
      " 10%|█         | 5/50 [00:56<10:33, 14.07s/it][I 2025-05-23 19:24:54,049] Trial 5 finished with value: 0.2565666735172272 and parameters: {'learning_rate': 0.00010916964175223582, 'batch_size': 128, 'epochs': 70, 'dropout1': 0.5683738946969586, 'dropout2': 0.35631993149902086, 'dropout3': 0.46524256210359205, 'dropout4': 0.48878184012869563, 'units1': 202, 'units2': 35, 'units3': 253, 'units4': 186, 'n_layers': 3}. Best is trial 1 with value: 0.2562015950679779.\n",
      " 12%|█▏        | 6/50 [01:00<07:51, 10.72s/it][I 2025-05-23 19:25:02,700] Trial 6 finished with value: 0.23036624491214752 and parameters: {'learning_rate': 0.0008323285293350796, 'batch_size': 128, 'epochs': 134, 'dropout1': 0.5241309763801586, 'dropout2': 0.2753948363156269, 'dropout3': 0.18659414111278186, 'dropout4': 0.38843302172876426, 'units1': 162, 'units2': 65, 'units3': 146, 'units4': 68, 'n_layers': 4}. Best is trial 6 with value: 0.23036624491214752.\n",
      " 14%|█▍        | 7/50 [01:09<07:11, 10.05s/it][I 2025-05-23 19:25:06,658] Trial 7 finished with value: 0.26060786843299866 and parameters: {'learning_rate': 0.0003581790772065412, 'batch_size': 64, 'epochs': 92, 'dropout1': 0.5259172231914607, 'dropout2': 0.1213007665075028, 'dropout3': 0.30124815216938716, 'dropout4': 0.5753231951149157, 'units1': 109, 'units2': 161, 'units3': 128, 'units4': 232, 'n_layers': 3}. Best is trial 6 with value: 0.23036624491214752.\n",
      " 16%|█▌        | 8/50 [01:13<05:40,  8.11s/it][I 2025-05-23 19:25:15,458] Trial 8 finished with value: 0.2339698076248169 and parameters: {'learning_rate': 7.093570063152967e-05, 'batch_size': 128, 'epochs': 140, 'dropout1': 0.1421293145625995, 'dropout2': 0.14670019782313184, 'dropout3': 0.39989079733486865, 'dropout4': 0.35890315270272444, 'units1': 140, 'units2': 251, 'units3': 84, 'units4': 123, 'n_layers': 3}. Best is trial 6 with value: 0.23036624491214752.\n",
      " 18%|█▊        | 9/50 [01:22<05:41,  8.32s/it][I 2025-05-23 19:25:26,537] Trial 9 finished with value: 0.24690605700016022 and parameters: {'learning_rate': 0.000750054937034724, 'batch_size': 64, 'epochs': 125, 'dropout1': 0.5726741891914271, 'dropout2': 0.42706064127762355, 'dropout3': 0.4082462261259445, 'dropout4': 0.2957822784806088, 'units1': 203, 'units2': 154, 'units3': 127, 'units4': 94, 'n_layers': 3}. Best is trial 6 with value: 0.23036624491214752.\n",
      " 20%|██        | 10/50 [01:33<06:06,  9.17s/it][I 2025-05-23 19:25:31,917] Trial 10 finished with value: 0.24104677140712738 and parameters: {'learning_rate': 0.002513268514669032, 'batch_size': 32, 'epochs': 53, 'dropout1': 0.4106651222963825, 'dropout2': 0.5866654044254946, 'dropout3': 0.1301091241936153, 'dropout4': 0.10008890622369121, 'units1': 66, 'units2': 80, 'units3': 46, 'units4': 32, 'n_layers': 4}. Best is trial 6 with value: 0.23036624491214752.\n",
      " 22%|██▏       | 11/50 [01:38<05:12,  8.01s/it][I 2025-05-23 19:25:38,008] Trial 11 finished with value: 0.24873460829257965 and parameters: {'learning_rate': 0.00011540781309653932, 'batch_size': 128, 'epochs': 147, 'dropout1': 0.1578684484410982, 'dropout2': 0.2396314740388456, 'dropout3': 0.24200883214718, 'dropout4': 0.4644001397589723, 'units1': 169, 'units2': 252, 'units3': 69, 'units4': 150, 'n_layers': 4}. Best is trial 6 with value: 0.23036624491214752.\n",
      " 24%|██▍       | 12/50 [01:44<04:42,  7.43s/it][I 2025-05-23 19:25:48,138] Trial 12 finished with value: 0.08679825812578201 and parameters: {'learning_rate': 0.0012393662928973904, 'batch_size': 128, 'epochs': 127, 'dropout1': 0.10089272824600759, 'dropout2': 0.2252311680797197, 'dropout3': 0.1017725848743729, 'dropout4': 0.45082896478218193, 'units1': 168, 'units2': 216, 'units3': 86, 'units4': 143, 'n_layers': 4}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 26%|██▌       | 13/50 [01:55<05:05,  8.25s/it][I 2025-05-23 19:25:59,566] Trial 13 finished with value: 0.20912574231624603 and parameters: {'learning_rate': 0.0015993031875174313, 'batch_size': 128, 'epochs': 121, 'dropout1': 0.44580240828894235, 'dropout2': 0.2524219528918318, 'dropout3': 0.12450265113233439, 'dropout4': 0.4754581370008686, 'units1': 181, 'units2': 204, 'units3': 173, 'units4': 156, 'n_layers': 4}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 28%|██▊       | 14/50 [02:06<05:31,  9.21s/it][I 2025-05-23 19:26:11,117] Trial 14 finished with value: 0.177112877368927 and parameters: {'learning_rate': 0.0020980707396404666, 'batch_size': 128, 'epochs': 114, 'dropout1': 0.44079369883177405, 'dropout2': 0.20681103616670793, 'dropout3': 0.1031237536829413, 'dropout4': 0.5894313660965964, 'units1': 201, 'units2': 213, 'units3': 180, 'units4': 165, 'n_layers': 4}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 30%|███       | 15/50 [02:18<05:46,  9.91s/it][I 2025-05-23 19:26:15,614] Trial 15 finished with value: 0.23570628464221954 and parameters: {'learning_rate': 0.005440275852894048, 'batch_size': 128, 'epochs': 108, 'dropout1': 0.4343521177309013, 'dropout2': 0.1922373235176385, 'dropout3': 0.20362732876244102, 'dropout4': 0.5768396333620764, 'units1': 216, 'units2': 201, 'units3': 191, 'units4': 182, 'n_layers': 4}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 32%|███▏      | 16/50 [02:22<04:41,  8.28s/it][I 2025-05-23 19:26:23,890] Trial 16 finished with value: 0.1585293412208557 and parameters: {'learning_rate': 0.002743696002792275, 'batch_size': 128, 'epochs': 103, 'dropout1': 0.2237623254037997, 'dropout2': 0.30586895807568776, 'dropout3': 0.10009017116131033, 'dropout4': 0.5071337444687443, 'units1': 100, 'units2': 205, 'units3': 93, 'units4': 184, 'n_layers': 4}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 34%|███▍      | 17/50 [02:30<04:33,  8.28s/it][I 2025-05-23 19:26:33,820] Trial 17 finished with value: 0.23493845760822296 and parameters: {'learning_rate': 0.0036573513222947084, 'batch_size': 32, 'epochs': 102, 'dropout1': 0.10957467861743292, 'dropout2': 0.3145944778576272, 'dropout3': 0.26967564680451395, 'dropout4': 0.5125883178190226, 'units1': 88, 'units2': 184, 'units3': 94, 'units4': 204, 'n_layers': 4}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 36%|███▌      | 18/50 [02:40<04:40,  8.78s/it][I 2025-05-23 19:26:39,611] Trial 18 finished with value: 0.2561225891113281 and parameters: {'learning_rate': 0.009522500575590563, 'batch_size': 16, 'epochs': 124, 'dropout1': 0.2195368129532507, 'dropout2': 0.42234077339739146, 'dropout3': 0.17599470510914328, 'dropout4': 0.5253066537674398, 'units1': 87, 'units2': 222, 'units3': 32, 'units4': 128, 'n_layers': 4}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 38%|███▊      | 19/50 [02:46<04:04,  7.88s/it][I 2025-05-23 19:26:46,241] Trial 19 finished with value: 0.18854674696922302 and parameters: {'learning_rate': 0.00114086071758136, 'batch_size': 128, 'epochs': 88, 'dropout1': 0.23610138313370688, 'dropout2': 0.3133314603465005, 'dropout3': 0.29490536671875867, 'dropout4': 0.4502934361951959, 'units1': 117, 'units2': 182, 'units3': 101, 'units4': 185, 'n_layers': 4}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 40%|████      | 20/50 [02:53<03:45,  7.50s/it][I 2025-05-23 19:26:49,198] Trial 20 finished with value: 0.2558766305446625 and parameters: {'learning_rate': 0.0002034188946593841, 'batch_size': 128, 'epochs': 105, 'dropout1': 0.10306604401567526, 'dropout2': 0.5082854591875343, 'dropout3': 0.5869137986725694, 'dropout4': 0.4365575306795665, 'units1': 34, 'units2': 124, 'units3': 61, 'units4': 139, 'n_layers': 4}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 42%|████▏     | 21/50 [02:56<02:58,  6.14s/it][I 2025-05-23 19:26:59,900] Trial 21 finished with value: 0.15225236117839813 and parameters: {'learning_rate': 0.0019342575317555363, 'batch_size': 128, 'epochs': 114, 'dropout1': 0.3606632165508258, 'dropout2': 0.1990353294335309, 'dropout3': 0.10586241756941481, 'dropout4': 0.5913722352088132, 'units1': 181, 'units2': 223, 'units3': 178, 'units4': 166, 'n_layers': 4}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 44%|████▍     | 22/50 [03:06<03:30,  7.51s/it][I 2025-05-23 19:27:12,177] Trial 22 finished with value: 0.1846076399087906 and parameters: {'learning_rate': 0.0034322371202401857, 'batch_size': 128, 'epochs': 131, 'dropout1': 0.35875589993912166, 'dropout2': 0.2904657510116164, 'dropout3': 0.1554243479119329, 'dropout4': 0.5354785611603541, 'units1': 150, 'units2': 227, 'units3': 109, 'units4': 256, 'n_layers': 4}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 46%|████▌     | 23/50 [03:19<04:01,  8.94s/it][I 2025-05-23 19:27:21,353] Trial 23 finished with value: 0.17009682953357697 and parameters: {'learning_rate': 0.0014414977154313916, 'batch_size': 128, 'epochs': 117, 'dropout1': 0.2801051469720933, 'dropout2': 0.18036312365429172, 'dropout3': 0.21425422739872407, 'dropout4': 0.5437463112913962, 'units1': 177, 'units2': 181, 'units3': 83, 'units4': 166, 'n_layers': 4}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 48%|████▊     | 24/50 [03:28<03:54,  9.01s/it][I 2025-05-23 19:27:34,499] Trial 24 finished with value: 0.10746396332979202 and parameters: {'learning_rate': 0.0038127922216676206, 'batch_size': 128, 'epochs': 150, 'dropout1': 0.1969948150347846, 'dropout2': 0.20547629248856664, 'dropout3': 0.10570945708380194, 'dropout4': 0.4256657290237443, 'units1': 129, 'units2': 232, 'units3': 152, 'units4': 189, 'n_layers': 4}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 50%|█████     | 25/50 [03:41<04:16, 10.25s/it][I 2025-05-23 19:27:47,132] Trial 25 finished with value: 0.13693661987781525 and parameters: {'learning_rate': 0.0006519073404714668, 'batch_size': 128, 'epochs': 150, 'dropout1': 0.15996143757872638, 'dropout2': 0.21841962823638822, 'dropout3': 0.15083290077317602, 'dropout4': 0.42267023857738234, 'units1': 133, 'units2': 234, 'units3': 157, 'units4': 105, 'n_layers': 4}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 52%|█████▏    | 26/50 [03:54<04:23, 10.97s/it][I 2025-05-23 19:28:26,328] Trial 26 finished with value: 0.09104481339454651 and parameters: {'learning_rate': 0.0005838357176364047, 'batch_size': 16, 'epochs': 150, 'dropout1': 0.1751674488894272, 'dropout2': 0.16388221172714404, 'dropout3': 0.15688869123638075, 'dropout4': 0.42287679162508307, 'units1': 129, 'units2': 236, 'units3': 156, 'units4': 87, 'n_layers': 4}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 54%|█████▍    | 27/50 [04:33<07:27, 19.44s/it][I 2025-05-23 19:29:06,253] Trial 27 finished with value: 0.10475742816925049 and parameters: {'learning_rate': 0.00021133366615695072, 'batch_size': 16, 'epochs': 141, 'dropout1': 0.18412938359430958, 'dropout2': 0.14924252999224702, 'dropout3': 0.23244972662223184, 'dropout4': 0.3184571858205215, 'units1': 155, 'units2': 255, 'units3': 199, 'units4': 83, 'n_layers': 4}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 56%|█████▌    | 28/50 [05:13<09:22, 25.58s/it][I 2025-05-23 19:29:36,889] Trial 28 finished with value: 0.2606540620326996 and parameters: {'learning_rate': 1.132319264159275e-05, 'batch_size': 16, 'epochs': 142, 'dropout1': 0.14358330546567669, 'dropout2': 0.16607315011082485, 'dropout3': 0.23962589877703297, 'dropout4': 0.2885341054210843, 'units1': 160, 'units2': 253, 'units3': 214, 'units4': 81, 'n_layers': 4}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 58%|█████▊    | 29/50 [05:43<09:29, 27.10s/it][I 2025-05-23 19:30:09,264] Trial 29 finished with value: 0.132645383477211 and parameters: {'learning_rate': 0.00021662221699533975, 'batch_size': 16, 'epochs': 131, 'dropout1': 0.2681801843935863, 'dropout2': 0.10698117429372142, 'dropout3': 0.3117162353945862, 'dropout4': 0.24273747346510086, 'units1': 227, 'units2': 192, 'units3': 207, 'units4': 45, 'n_layers': 3}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 60%|██████    | 30/50 [06:16<09:33, 28.68s/it][I 2025-05-23 19:30:50,864] Trial 30 finished with value: 0.16904763877391815 and parameters: {'learning_rate': 0.00019891314452050204, 'batch_size': 16, 'epochs': 136, 'dropout1': 0.31302814376279603, 'dropout2': 0.14825773542495746, 'dropout3': 0.16235316974720854, 'dropout4': 0.24474917223020806, 'units1': 158, 'units2': 242, 'units3': 234, 'units4': 54, 'n_layers': 4}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 62%|██████▏   | 31/50 [06:57<10:18, 32.56s/it][I 2025-05-23 19:31:31,657] Trial 31 finished with value: 0.11989321559667587 and parameters: {'learning_rate': 0.00044035729700796894, 'batch_size': 16, 'epochs': 146, 'dropout1': 0.18416607017849862, 'dropout2': 0.24175817119944604, 'dropout3': 0.20698896180954987, 'dropout4': 0.4229868994556494, 'units1': 127, 'units2': 256, 'units3': 200, 'units4': 104, 'n_layers': 4}. Best is trial 12 with value: 0.08679825812578201.\n",
      " 64%|██████▍   | 32/50 [07:38<10:30, 35.03s/it][I 2025-05-23 19:32:10,391] Trial 32 finished with value: 0.06980975717306137 and parameters: {'learning_rate': 0.0009774501994633514, 'batch_size': 16, 'epochs': 149, 'dropout1': 0.12511657778112154, 'dropout2': 0.16872832087794348, 'dropout3': 0.1393163795059462, 'dropout4': 0.3546740625513819, 'units1': 149, 'units2': 218, 'units3': 160, 'units4': 94, 'n_layers': 4}. Best is trial 32 with value: 0.06980975717306137.\n",
      " 66%|██████▌   | 33/50 [08:17<10:14, 36.14s/it][I 2025-05-23 19:32:47,699] Trial 33 finished with value: 0.06239191070199013 and parameters: {'learning_rate': 0.000996057232413194, 'batch_size': 16, 'epochs': 142, 'dropout1': 0.1207632731556716, 'dropout2': 0.13513792259110022, 'dropout3': 0.14600939088919987, 'dropout4': 0.3614094031186118, 'units1': 187, 'units2': 216, 'units3': 164, 'units4': 88, 'n_layers': 4}. Best is trial 33 with value: 0.06239191070199013.\n",
      " 68%|██████▊   | 34/50 [08:54<09:43, 36.49s/it][I 2025-05-23 19:33:17,450] Trial 34 finished with value: 0.07411128282546997 and parameters: {'learning_rate': 0.0009580749446470463, 'batch_size': 16, 'epochs': 129, 'dropout1': 0.12226047255751947, 'dropout2': 0.12915907639101523, 'dropout3': 0.14096225752460131, 'dropout4': 0.36397528811101887, 'units1': 192, 'units2': 173, 'units3': 168, 'units4': 65, 'n_layers': 4}. Best is trial 33 with value: 0.06239191070199013.\n",
      " 70%|███████   | 35/50 [09:24<08:37, 34.47s/it][I 2025-05-23 19:33:47,175] Trial 35 finished with value: 0.06439869105815887 and parameters: {'learning_rate': 0.0010681832423218658, 'batch_size': 16, 'epochs': 128, 'dropout1': 0.12358472330104053, 'dropout2': 0.10742160673436069, 'dropout3': 0.13432444487699952, 'dropout4': 0.33265887580447695, 'units1': 241, 'units2': 172, 'units3': 137, 'units4': 69, 'n_layers': 4}. Best is trial 33 with value: 0.06239191070199013.\n",
      " 72%|███████▏  | 36/50 [09:54<07:42, 33.05s/it][I 2025-05-23 19:34:18,678] Trial 36 finished with value: 0.07259862869977951 and parameters: {'learning_rate': 0.0009559840124772119, 'batch_size': 16, 'epochs': 136, 'dropout1': 0.1275787428728859, 'dropout2': 0.1007583188498731, 'dropout3': 0.13999713933630833, 'dropout4': 0.35918992204946665, 'units1': 253, 'units2': 134, 'units3': 169, 'units4': 65, 'n_layers': 4}. Best is trial 33 with value: 0.06239191070199013.\n",
      " 74%|███████▍  | 37/50 [10:25<07:03, 32.58s/it][I 2025-05-23 19:34:23,626] Trial 37 finished with value: 0.2538127601146698 and parameters: {'learning_rate': 0.005444171433824575, 'batch_size': 16, 'epochs': 136, 'dropout1': 0.13751214474519158, 'dropout2': 0.104321924343798, 'dropout3': 0.19785071063992443, 'dropout4': 0.3347276041907736, 'units1': 256, 'units2': 134, 'units3': 134, 'units4': 54, 'n_layers': 4}. Best is trial 33 with value: 0.06239191070199013.\n",
      " 76%|███████▌  | 38/50 [10:30<04:51, 24.29s/it][I 2025-05-23 19:34:50,445] Trial 38 finished with value: 0.09856100380420685 and parameters: {'learning_rate': 0.00046814377973233644, 'batch_size': 16, 'epochs': 143, 'dropout1': 0.24768860880180765, 'dropout2': 0.10069156224032812, 'dropout3': 0.334523954482254, 'dropout4': 0.39822933452033094, 'units1': 240, 'units2': 111, 'units3': 141, 'units4': 32, 'n_layers': 3}. Best is trial 33 with value: 0.06239191070199013.\n",
      " 78%|███████▊  | 39/50 [10:57<04:35, 25.05s/it][I 2025-05-23 19:35:21,232] Trial 39 finished with value: 0.09870939701795578 and parameters: {'learning_rate': 0.0002795203835442001, 'batch_size': 16, 'epochs': 136, 'dropout1': 0.1258693997594064, 'dropout2': 0.12740590670327842, 'dropout3': 0.2598960869107185, 'dropout4': 0.26959421051056975, 'units1': 223, 'units2': 145, 'units3': 163, 'units4': 74, 'n_layers': 4}. Best is trial 33 with value: 0.06239191070199013.\n",
      " 80%|████████  | 40/50 [11:28<04:27, 26.77s/it][I 2025-05-23 19:35:32,624] Trial 40 finished with value: 0.10866983979940414 and parameters: {'learning_rate': 0.0008769224049753186, 'batch_size': 64, 'epochs': 120, 'dropout1': 0.20383445907555559, 'dropout2': 0.17046636516065336, 'dropout3': 0.13429192138007492, 'dropout4': 0.34808146899536496, 'units1': 255, 'units2': 95, 'units3': 185, 'units4': 55, 'n_layers': 4}. Best is trial 33 with value: 0.06239191070199013.\n",
      " 82%|████████▏ | 41/50 [11:39<03:19, 22.16s/it][I 2025-05-23 19:36:05,961] Trial 41 finished with value: 0.07455850392580032 and parameters: {'learning_rate': 0.0010749157690595006, 'batch_size': 16, 'epochs': 130, 'dropout1': 0.1261801396727709, 'dropout2': 0.13326921635985003, 'dropout3': 0.17304995379346289, 'dropout4': 0.36978002741322363, 'units1': 191, 'units2': 170, 'units3': 168, 'units4': 64, 'n_layers': 4}. Best is trial 33 with value: 0.06239191070199013.\n",
      " 84%|████████▍ | 42/50 [12:12<03:24, 25.51s/it][I 2025-05-23 19:36:39,323] Trial 42 finished with value: 0.06825681030750275 and parameters: {'learning_rate': 0.0008243320876386703, 'batch_size': 16, 'epochs': 139, 'dropout1': 0.16386409122533444, 'dropout2': 0.1217086464872519, 'dropout3': 0.1347931889112949, 'dropout4': 0.38611118185264837, 'units1': 241, 'units2': 169, 'units3': 119, 'units4': 97, 'n_layers': 4}. Best is trial 33 with value: 0.06239191070199013.\n",
      " 86%|████████▌ | 43/50 [12:46<03:15, 27.87s/it][I 2025-05-23 19:37:11,359] Trial 43 finished with value: 0.0728364959359169 and parameters: {'learning_rate': 0.0006193728702532695, 'batch_size': 16, 'epochs': 140, 'dropout1': 0.16130488602613569, 'dropout2': 0.12654632137380228, 'dropout3': 0.17956639648844358, 'dropout4': 0.3132669406010118, 'units1': 238, 'units2': 148, 'units3': 115, 'units4': 95, 'n_layers': 4}. Best is trial 33 with value: 0.06239191070199013.\n",
      " 88%|████████▊ | 44/50 [13:18<02:54, 29.12s/it][I 2025-05-23 19:37:40,434] Trial 44 finished with value: 0.10311895608901978 and parameters: {'learning_rate': 0.0015349387731218348, 'batch_size': 16, 'epochs': 144, 'dropout1': 0.14972267473242762, 'dropout2': 0.15548246626400386, 'dropout3': 0.13623081121117195, 'dropout4': 0.39134663438069667, 'units1': 250, 'units2': 161, 'units3': 143, 'units4': 113, 'n_layers': 4}. Best is trial 33 with value: 0.06239191070199013.\n",
      " 90%|█████████ | 45/50 [13:47<02:25, 29.10s/it][I 2025-05-23 19:37:58,298] Trial 45 finished with value: 0.11643338203430176 and parameters: {'learning_rate': 0.0002961829959026781, 'batch_size': 32, 'epochs': 136, 'dropout1': 0.17608660145465377, 'dropout2': 0.10302983708387789, 'dropout3': 0.22211688619058034, 'dropout4': 0.3403085826958171, 'units1': 216, 'units2': 134, 'units3': 122, 'units4': 100, 'n_layers': 4}. Best is trial 33 with value: 0.06239191070199013.\n",
      " 92%|█████████▏| 46/50 [14:05<01:42, 25.73s/it][I 2025-05-23 19:38:14,223] Trial 46 finished with value: 0.11674205958843231 and parameters: {'learning_rate': 0.0003999931736618263, 'batch_size': 16, 'epochs': 64, 'dropout1': 0.12396882452713609, 'dropout2': 0.17717457841834724, 'dropout3': 0.4909813020399131, 'dropout4': 0.396966989910745, 'units1': 233, 'units2': 194, 'units3': 134, 'units4': 125, 'n_layers': 3}. Best is trial 33 with value: 0.06239191070199013.\n",
      " 94%|█████████▍| 47/50 [14:21<01:08, 22.79s/it][I 2025-05-23 19:38:22,254] Trial 47 finished with value: 0.15862902998924255 and parameters: {'learning_rate': 0.0007832985257488097, 'batch_size': 64, 'epochs': 95, 'dropout1': 0.20192317782032815, 'dropout2': 0.267923563845514, 'dropout3': 0.1312996050558527, 'dropout4': 0.2042430013831175, 'units1': 211, 'units2': 55, 'units3': 148, 'units4': 74, 'n_layers': 4}. Best is trial 33 with value: 0.06239191070199013.\n",
      " 96%|█████████▌| 48/50 [14:29<00:36, 18.36s/it][I 2025-05-23 19:38:48,403] Trial 48 finished with value: 0.10186521708965302 and parameters: {'learning_rate': 0.0016493492744161242, 'batch_size': 16, 'epochs': 133, 'dropout1': 0.10396947885357488, 'dropout2': 0.12423964097680731, 'dropout3': 0.18872684006009088, 'dropout4': 0.2936746266732052, 'units1': 240, 'units2': 106, 'units3': 111, 'units4': 44, 'n_layers': 4}. Best is trial 33 with value: 0.06239191070199013.\n",
      " 98%|█████████▊| 49/50 [14:55<00:20, 20.70s/it][I 2025-05-23 19:39:19,334] Trial 49 finished with value: 0.1351558268070221 and parameters: {'learning_rate': 0.002408893618184494, 'batch_size': 16, 'epochs': 146, 'dropout1': 0.16489604362557286, 'dropout2': 0.18827212279346633, 'dropout3': 0.12373122807840231, 'dropout4': 0.37256151430134693, 'units1': 247, 'units2': 155, 'units3': 135, 'units4': 87, 'n_layers': 4}. Best is trial 33 with value: 0.06239191070199013.\n",
      "100%|██████████| 50/50 [15:26<00:00, 18.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value (MAE): 0.06239191070199013\n",
      "  Params:\n",
      "    learning_rate: 0.000996057232413194\n",
      "    batch_size: 16\n",
      "    epochs: 142\n",
      "    dropout1: 0.1207632731556716\n",
      "    dropout2: 0.13513792259110022\n",
      "    dropout3: 0.14600939088919987\n",
      "    dropout4: 0.3614094031186118\n",
      "    units1: 187\n",
      "    units2: 216\n",
      "    units3: 164\n",
      "    units4: 88\n",
      "    n_layers: 4\n",
      "Epoch 1/142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - loss: 0.3163 - mean_absolute_error: 0.3163\n",
      "Epoch 2/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 0.2713 - mean_absolute_error: 0.2713\n",
      "Epoch 3/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 0.2681 - mean_absolute_error: 0.2681\n",
      "Epoch 4/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - loss: 0.2538 - mean_absolute_error: 0.2538\n",
      "Epoch 5/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - loss: 0.2534 - mean_absolute_error: 0.2534\n",
      "Epoch 6/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 0.2442 - mean_absolute_error: 0.2442\n",
      "Epoch 7/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 0.2472 - mean_absolute_error: 0.2472\n",
      "Epoch 8/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.2444 - mean_absolute_error: 0.2444\n",
      "Epoch 9/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 0.2334 - mean_absolute_error: 0.2334\n",
      "Epoch 10/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.2350 - mean_absolute_error: 0.2350\n",
      "Epoch 11/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 0.2337 - mean_absolute_error: 0.2337\n",
      "Epoch 12/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 0.2356 - mean_absolute_error: 0.2356\n",
      "Epoch 13/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 0.2316 - mean_absolute_error: 0.2316\n",
      "Epoch 14/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.2204 - mean_absolute_error: 0.2204\n",
      "Epoch 15/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 0.2235 - mean_absolute_error: 0.2235\n",
      "Epoch 16/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2257 - mean_absolute_error: 0.2257\n",
      "Epoch 17/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - loss: 0.2143 - mean_absolute_error: 0.2143\n",
      "Epoch 18/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.2163 - mean_absolute_error: 0.2163\n",
      "Epoch 19/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2157 - mean_absolute_error: 0.2157 \n",
      "Epoch 20/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.2096 - mean_absolute_error: 0.2096\n",
      "Epoch 21/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2075 - mean_absolute_error: 0.2075\n",
      "Epoch 22/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2054 - mean_absolute_error: 0.2054 \n",
      "Epoch 23/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1986 - mean_absolute_error: 0.1986\n",
      "Epoch 24/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 0.1928 - mean_absolute_error: 0.1928\n",
      "Epoch 25/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1935 - mean_absolute_error: 0.1935  \n",
      "Epoch 26/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.1909 - mean_absolute_error: 0.1909\n",
      "Epoch 27/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.1862 - mean_absolute_error: 0.1862\n",
      "Epoch 28/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.1882 - mean_absolute_error: 0.1882\n",
      "Epoch 29/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.1835 - mean_absolute_error: 0.1835\n",
      "Epoch 30/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.1800 - mean_absolute_error: 0.1800\n",
      "Epoch 31/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1788 - mean_absolute_error: 0.1788  \n",
      "Epoch 32/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1782 - mean_absolute_error: 0.1782\n",
      "Epoch 33/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 0.1787 - mean_absolute_error: 0.1787\n",
      "Epoch 34/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1697 - mean_absolute_error: 0.1697\n",
      "Epoch 35/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 0.1721 - mean_absolute_error: 0.1721\n",
      "Epoch 36/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1692 - mean_absolute_error: 0.1692\n",
      "Epoch 37/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1642 - mean_absolute_error: 0.1642\n",
      "Epoch 38/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.1630 - mean_absolute_error: 0.1630\n",
      "Epoch 39/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - loss: 0.1603 - mean_absolute_error: 0.1603\n",
      "Epoch 40/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.1613 - mean_absolute_error: 0.1613\n",
      "Epoch 41/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1580 - mean_absolute_error: 0.1580\n",
      "Epoch 42/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.1571 - mean_absolute_error: 0.1571\n",
      "Epoch 43/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 0.1604 - mean_absolute_error: 0.1604\n",
      "Epoch 44/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.1568 - mean_absolute_error: 0.1568\n",
      "Epoch 45/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.1531 - mean_absolute_error: 0.1531\n",
      "Epoch 46/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.1548 - mean_absolute_error: 0.1548\n",
      "Epoch 47/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1534 - mean_absolute_error: 0.1534  \n",
      "Epoch 48/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1442 - mean_absolute_error: 0.1442  \n",
      "Epoch 49/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1465 - mean_absolute_error: 0.1465\n",
      "Epoch 50/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.1497 - mean_absolute_error: 0.1497\n",
      "Epoch 51/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1481 - mean_absolute_error: 0.1481\n",
      "Epoch 52/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1490 - mean_absolute_error: 0.1490\n",
      "Epoch 53/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.1431 - mean_absolute_error: 0.1431\n",
      "Epoch 54/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1407 - mean_absolute_error: 0.1407\n",
      "Epoch 55/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1417 - mean_absolute_error: 0.1417\n",
      "Epoch 56/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - loss: 0.1447 - mean_absolute_error: 0.1447\n",
      "Epoch 57/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.1409 - mean_absolute_error: 0.1409\n",
      "Epoch 58/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1400 - mean_absolute_error: 0.1400\n",
      "Epoch 59/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.1401 - mean_absolute_error: 0.1401\n",
      "Epoch 60/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1373 - mean_absolute_error: 0.1373\n",
      "Epoch 61/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1371 - mean_absolute_error: 0.1371\n",
      "Epoch 62/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.1389 - mean_absolute_error: 0.1389\n",
      "Epoch 63/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 0.1357 - mean_absolute_error: 0.1357\n",
      "Epoch 64/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.1383 - mean_absolute_error: 0.1383\n",
      "Epoch 65/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1376 - mean_absolute_error: 0.1376\n",
      "Epoch 66/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1345 - mean_absolute_error: 0.1345\n",
      "Epoch 67/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1349 - mean_absolute_error: 0.1349  \n",
      "Epoch 68/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1325 - mean_absolute_error: 0.1325\n",
      "Epoch 69/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.1290 - mean_absolute_error: 0.1290\n",
      "Epoch 70/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.1263 - mean_absolute_error: 0.1263\n",
      "Epoch 71/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1349 - mean_absolute_error: 0.1349\n",
      "Epoch 72/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1287 - mean_absolute_error: 0.1287\n",
      "Epoch 73/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.1289 - mean_absolute_error: 0.1289\n",
      "Epoch 74/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1297 - mean_absolute_error: 0.1297\n",
      "Epoch 75/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1259 - mean_absolute_error: 0.1259  \n",
      "Epoch 76/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1294 - mean_absolute_error: 0.1294\n",
      "Epoch 77/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1253 - mean_absolute_error: 0.1253\n",
      "Epoch 78/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1262 - mean_absolute_error: 0.1262\n",
      "Epoch 79/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.1268 - mean_absolute_error: 0.1268\n",
      "Epoch 80/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1258 - mean_absolute_error: 0.1258\n",
      "Epoch 81/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.1249 - mean_absolute_error: 0.1249\n",
      "Epoch 82/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1238 - mean_absolute_error: 0.1238  \n",
      "Epoch 83/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1198 - mean_absolute_error: 0.1198\n",
      "Epoch 84/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 0.1183 - mean_absolute_error: 0.1183\n",
      "Epoch 85/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 0.1235 - mean_absolute_error: 0.1235\n",
      "Epoch 86/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 0.1236 - mean_absolute_error: 0.1236\n",
      "Epoch 87/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1207 - mean_absolute_error: 0.1207\n",
      "Epoch 88/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.1242 - mean_absolute_error: 0.1242\n",
      "Epoch 89/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.1175 - mean_absolute_error: 0.1175\n",
      "Epoch 90/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.1186 - mean_absolute_error: 0.1186\n",
      "Epoch 91/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1211 - mean_absolute_error: 0.1211\n",
      "Epoch 92/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1236 - mean_absolute_error: 0.1236\n",
      "Epoch 93/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 0.1189 - mean_absolute_error: 0.1189\n",
      "Epoch 94/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - loss: 0.1216 - mean_absolute_error: 0.1216\n",
      "Epoch 95/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.1180 - mean_absolute_error: 0.1180\n",
      "Epoch 96/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1175 - mean_absolute_error: 0.1175\n",
      "Epoch 97/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1161 - mean_absolute_error: 0.1161\n",
      "Epoch 98/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1188 - mean_absolute_error: 0.1188\n",
      "Epoch 99/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1182 - mean_absolute_error: 0.1182  \n",
      "Epoch 100/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1143 - mean_absolute_error: 0.1143\n",
      "Epoch 101/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.1145 - mean_absolute_error: 0.1145\n",
      "Epoch 102/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.1130 - mean_absolute_error: 0.1130\n",
      "Epoch 103/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1129 - mean_absolute_error: 0.1129\n",
      "Epoch 104/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 0.1171 - mean_absolute_error: 0.1171\n",
      "Epoch 105/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1135 - mean_absolute_error: 0.1135\n",
      "Epoch 106/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 0.1131 - mean_absolute_error: 0.1131\n",
      "Epoch 107/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1170 - mean_absolute_error: 0.1170  \n",
      "Epoch 108/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - loss: 0.1129 - mean_absolute_error: 0.1129\n",
      "Epoch 109/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - loss: 0.1137 - mean_absolute_error: 0.1137\n",
      "Epoch 110/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1119 - mean_absolute_error: 0.1119  \n",
      "Epoch 111/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1118 - mean_absolute_error: 0.1118\n",
      "Epoch 112/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1109 - mean_absolute_error: 0.1109  \n",
      "Epoch 113/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.1112 - mean_absolute_error: 0.1112\n",
      "Epoch 114/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1127 - mean_absolute_error: 0.1127  \n",
      "Epoch 115/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.1122 - mean_absolute_error: 0.1122\n",
      "Epoch 116/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1152 - mean_absolute_error: 0.1152\n",
      "Epoch 117/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1088 - mean_absolute_error: 0.1088\n",
      "Epoch 118/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1099 - mean_absolute_error: 0.1099  \n",
      "Epoch 119/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.1124 - mean_absolute_error: 0.1124\n",
      "Epoch 120/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.1045 - mean_absolute_error: 0.1045\n",
      "Epoch 121/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.1117 - mean_absolute_error: 0.1117\n",
      "Epoch 122/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1090 - mean_absolute_error: 0.1090   \n",
      "Epoch 123/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1069 - mean_absolute_error: 0.1069\n",
      "Epoch 124/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1049 - mean_absolute_error: 0.1049  \n",
      "Epoch 125/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1104 - mean_absolute_error: 0.1104\n",
      "Epoch 126/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1070 - mean_absolute_error: 0.1070  \n",
      "Epoch 127/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1067 - mean_absolute_error: 0.1067\n",
      "Epoch 128/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1087 - mean_absolute_error: 0.1087\n",
      "Epoch 129/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1105 - mean_absolute_error: 0.1105\n",
      "Epoch 130/142\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1101 - mean_absolute_error: 0.1101\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import optuna\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1) 데이터 불러오기\n",
    "train = pd.read_csv(\"../../data/processed/processed_train.csv\")\n",
    "test = pd.read_csv(\"../../data/processed/processed_test.csv\")\n",
    "\n",
    "# 2) X, y 분리\n",
    "X = train.drop(columns=['ID', '성공확률'])\n",
    "y = train['성공확률']\n",
    "\n",
    "# 3) 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test = test.drop(columns=['ID'])\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Optuna 목적 함수\n",
    "def objective(trial):\n",
    "    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "    epochs = trial.suggest_int('epochs', 50, 150)\n",
    "    dropout_rates = [trial.suggest_float(f'dropout{i}', 0.1, 0.6) for i in range(1, 5)]\n",
    "    units = [trial.suggest_int(f'units{i}', 32, 256) for i in range(1, 5)]\n",
    "    n_layers = trial.suggest_int('n_layers', 3, 4)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_scaled.shape[1],)))\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        model.add(Dense(units[i], activation='relu'))\n",
    "        model.add(Dropout(dropout_rates[i]))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='mean_absolute_error',\n",
    "                  metrics=['mean_absolute_error'])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_scaled, y, epochs=epochs, batch_size=batch_size,\n",
    "              verbose=0, callbacks=[early_stop])\n",
    "\n",
    "    loss = model.evaluate(X_scaled, y, verbose=0)[0]\n",
    "    return loss\n",
    "\n",
    "# Optuna 스터디 & tqdm 연동\n",
    "n_trials = 50\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "with tqdm(total=n_trials) as pbar:\n",
    "    def tqdm_callback(study, trial):\n",
    "        pbar.update(1)\n",
    "    study.optimize(objective, n_trials=n_trials, callbacks=[tqdm_callback])\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value (MAE): {trial.value}\")\n",
    "print(\"  Params:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# 베스트 하이퍼파라미터로 최종 모델 학습 및 예측\n",
    "best_params = trial.params\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_scaled.shape[1],)))\n",
    "for i in range(best_params['n_layers']):\n",
    "    model.add(Dense(best_params[f'units{i+1}'], activation='relu'))\n",
    "    model.add(Dropout(best_params[f'dropout{i+1}']))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']),\n",
    "              loss='mean_absolute_error',\n",
    "              metrics=['mean_absolute_error'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_scaled, y, epochs=best_params['epochs'], batch_size=best_params['batch_size'],\n",
    "          verbose=1, callbacks=[early_stop])\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "y_test_pred = model.predict(X_test_scaled).flatten()\n",
    "\n",
    "# 제출 파일 생성\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test['ID'],\n",
    "    '성공확률': y_test_pred\n",
    "})\n",
    "submission['성공확률'] = submission['성공확률'].clip(0, 1)  # 필요 시 클리핑\n",
    "\n",
    "submission.to_csv('../../data/output/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bdd7d60-186c-4582-addd-d6d8f34928b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>성공확률</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>0.441260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>0.329026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>0.639163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>0.311008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>0.861093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>TEST_1750</td>\n",
       "      <td>0.710341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>TEST_1751</td>\n",
       "      <td>0.547599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>TEST_1752</td>\n",
       "      <td>0.322759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>TEST_1753</td>\n",
       "      <td>0.698343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>TEST_1754</td>\n",
       "      <td>0.247008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1755 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID      성공확률\n",
       "0     TEST_0000  0.441260\n",
       "1     TEST_0001  0.329026\n",
       "2     TEST_0002  0.639163\n",
       "3     TEST_0003  0.311008\n",
       "4     TEST_0004  0.861093\n",
       "...         ...       ...\n",
       "1750  TEST_1750  0.710341\n",
       "1751  TEST_1751  0.547599\n",
       "1752  TEST_1752  0.322759\n",
       "1753  TEST_1753  0.698343\n",
       "1754  TEST_1754  0.247008\n",
       "\n",
       "[1755 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dfab5a2-7094-476d-b4ed-50aa5b3f3c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "성공확률\n",
       "0.750    590\n",
       "0.625    579\n",
       "0.250    574\n",
       "0.375    561\n",
       "0.500    559\n",
       "0.875    548\n",
       "0.000    490\n",
       "1.000    475\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['성공확률'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82600a88-b1a4-4cb6-98ac-2fbd6903f433",
   "metadata": {},
   "source": [
    "# 프로젝트 계획 요약\n",
    "\n",
    "## 1. 데이터 이해 및 전처리\n",
    "- 성공확률이 0.1 단위로 구분된 이산형 값임을 확인\n",
    "- 범주형 변수 원핫 인코딩, 수치형 변수 정규화 적용\n",
    "- 성공확률을 클래스(분류 레이블)로 변환 (예: 0.1 → 클래스 1, 0.2 → 클래스 2 ...)\n",
    "\n",
    "## 2. 문제 정의\n",
    "- 성공확률 예측 → 회귀보다는 분류 문제로 전환하여 접근\n",
    "- 다중 클래스 분류 문제로 모델 학습\n",
    "\n",
    "## 3. 모델링\n",
    "- 신경망 모델 설계 (MLP 기반 다중 은닉층)\n",
    "- 하이퍼파라미터 튜닝 (Optuna 활용)\n",
    "  - 은닉층 수, 유닛 수, 드롭아웃 비율, 학습률, 배치사이즈, 에포크 범위 등 폭넓게 설정\n",
    "- 조기 종료(EarlyStopping) 적용\n",
    "\n",
    "## 4. 학습 및 검증\n",
    "- 교차검증 또는 Hold-out 검증으로 과적합 방지 및 일반화 평가\n",
    "- MAE 외 분류 정확도 등 다양한 평가 지표 활용\n",
    "\n",
    "## 5. 예측 및 제출\n",
    "- 테스트 데이터에 대해 클래스 예측 수행\n",
    "- 예측 클래스 → 성공확률 값으로 매핑하여 결과 생성\n",
    "- 제출 파일 생성 및 평가\n",
    "\n",
    "## 6. 향후 개선 및 확장\n",
    "- 분류+회귀 혼합 모델 고려\n",
    "- 샘플 가중치, 손실 함수 커스터마이징 등 불균형 및 비대칭 분포 대응 전략 적용\n",
    "- 다양한 신경망 아키텍처 실험 (CNN, Transformer 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ced7b-53c4-4a62-8f16-80c03bfc9e68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
